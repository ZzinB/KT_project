{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["\n","\n","\n","+\n","+# **저시력자를 위한 원화 화폐 분류**\n","---\n","- 본 과제는 UltraLytics YOLO v5 모델 사용을 권장합니다.\n","    - 본 파일의 목차는 UltraLytics YOLO v5에 맞게 작성되어 있습니다.\n","    - 다른 모델을 찾아서 사용하셔도 좋습니다.\n","    - 산출물이 잘 나오면 됩니다 : )---"],"metadata":{"id":"XT7PRhnMf-kI"}},{"cell_type":"markdown","source":["## 0.미션\n","---\n","- **과제 수행 목표**\n","    - 본 과제는 Object Detection 문제입니다.\n","    - Object Detection 문제로 접근하기 위해 **데이터셋 전처리**를 하셔야 합니다.\n","    - 데이터셋 : money_dataset.zip\n","        1. 데이터셋은 압축 파일로 제공됩니다.\n","        2. 압축 파일 안에는 화폐마다 폴더가 개별적으로 존재합니다.\n","        3. 폴더 안에는 화폐 이미지와 화폐 정보가 담긴 json 파일이 있습니다.\n","    - 여러분이 직접 촬영한 화폐 사진들을 탐지 과정에서 이용 해보세요.\n","    - 이미지에 화폐 하나만 나오게 촬영하는 것은 지양해주세요.\n","    - 다양한 방법으로 화폐를 촬영하고 결과를 확인해보세요.\n","        - ex 1) 화폐의 모든 종류를 한 이미지에 나오게 촬영\n","        - ex 2) 여러 화폐를 겹치게 하여 촬영\n","---\n","- **Key Point**\n","    1. 모델에 맞는 폴더 구조 확인\n","    2. 이미지 축소 비율에 맞춰 좌표값 변경\n","        - 좌표를 이미지 리사이즈한 비율로 변경\n","    3. 모델에 맞는 정보 추출/형식 변경\n","        - json 파일에서 정보 추출 및 모델 형식에 맞게 변경\n","    4. 화폐당 하나의 클래스로 변경\n","        - 총 8개 클래스\n","    5. 모델 선택 필요\n","---"],"metadata":{"id":"47D2vGDYdCOz"}},{"cell_type":"markdown","source":["## 1.환경설정"],"metadata":{"id":"aZon1K-Ag9be"}},{"cell_type":"markdown","source":["### (1) 구글 드라이브 연동\n","---\n","- 아래의 코드 셀을 반드시 실행시켜야 합니다.\n","---"],"metadata":{"id":"CMgnHN9ZBF05"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"xCplyiojBFwh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679631298032,"user_tz":-540,"elapsed":2317,"user":{"displayName":"이신비","userId":"04527371589362270556"}},"outputId":"315f6760-29cb-46b9-b6e1-cc60a06cf8fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["### (2) 데이터셋 불러오기\n","---\n","- **세부요구사항**\n","    - 데이터셋 파일의 압축을 해제하세요.\n","---\n","- 예제 코드에서는 zipfile 모듈을 이용하였습니다.\n","    - [zipfile document](https://docs.python.org/3/library/zipfile.html#zipfile-objects)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"],"metadata":{"id":"J8vjv0acBAV4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bkSa5ejf8LMe"},"outputs":[],"source":["import zipfile"]},{"cell_type":"code","source":["# 데이터셋 압축 파일 경로 : 유저별로 상이할 수 있음\n","dataset_path = '/content/drive/MyDrive/Datasets/'\n","file_path = dataset_path + 'money_dataset.zip'\n","money_data = zipfile.ZipFile(file_path)"],"metadata":{"id":"N4cdpkRv86QQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 압축 해제\n","money_data.extractall('/content/Dataset/')"],"metadata":{"id":"TDAyDRLT9hZS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.데이터 전처리"],"metadata":{"id":"QyEd-WNIhoSc"}},{"cell_type":"markdown","source":["### (1) 폴더 구조 생성 및 파일 이동\n","---\n","- **세부요구사항**\n","    -  모델에서 요구하는 폴더 구조를 만들어야 합니다.\n","        - Hint : Image와 Label을 구분하는 폴더를 만들어 주세요\n","---\n","- 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n","    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"],"metadata":{"id":"P81d6utx-3LY"}},{"cell_type":"code","source":["# 1.폴더 구조 만들기\n","!mkdir /content/Dataset/images;\n","!mkdir /content/Dataset/images/train; mkdir /content/Dataset/images/val\n","\n","!mkdir /content/Dataset/labels;\n","!mkdir /content/Dataset/labels/train; mkdir /content/Dataset/labels/val\n","\n","!mkdir /content/Dataset/json;\n","!mkdir /content/Dataset/json/10; mkdir /content/Dataset/json/50; mkdir /content/Dataset/json/100;mkdir /content/Dataset/json/500;mkdir /content/Dataset/json/1000;mkdir /content/Dataset/json/5000;mkdir /content/Dataset/json/10000;mkdir /content/Dataset/json/50000\n","!mkdir /content/Dataset/jpg;\n","!mkdir /content/Dataset/jpg/10; mkdir /content/Dataset/jpg/50; mkdir /content/Dataset/jpg/100; mkdir /content/Dataset/jpg/500; mkdir /content/Dataset/jpg/1000; mkdir /content/Dataset/jpg/5000; mkdir /content/Dataset/jpg/10000; mkdir /content/Dataset/jpg/50000"],"metadata":{"id":"YBqCJU5z_UI8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import glob, shutil"],"metadata":{"id":"UuchlNA_DftJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Dataset metadata 입력\n","won_list = ['10', '50', '100', '500', '1000', '5000', '10000', '50000']\n","data_path = '/content/Dataset/'"],"metadata":{"id":"Q3lnYcLS_UOy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","- 데이터를 Training set | Validation set으로 분할하세요.\n","    - 예시 : Training과 Validation은 8:2로 분리\n","- Hint : 이미지 데이터는 /images에, JSON 데이터는 /labels에 넣어주세요\n","    - 예시 : /dataset/images/train, /dataset/labels/train\n","    - 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n","    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n","\n","    ※ 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","    \n","---"],"metadata":{"id":"ihJgeqXJG1Ml"}},{"cell_type":"code","source":["import os\n","data_path_labels = '/content/Dataset/json'\n","data_path_images = '/content/Dataset/jpg'\n","for i in range (8):\n","    for path in os.listdir(data_path + won_list[i]):\n","        if path.split('.')[-1] == 'json':\n","            shutil.move(data_path + won_list[i]+'/'+path, data_path_labels+'/'+won_list[i])\n","        else:\n","            shutil.move(data_path + won_list[i]+'/'+path, data_path_images+'/'+won_list[i])"],"metadata":{"id":"NFINgDLJYyId"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["########################\n","# 이 셀부터 코드 작성하세요\n","########################\n","# 3. 데이터를 Training set | Validation set으로 분할하세요.\n","!pip install split-folders\n","import splitfolders\n","splitfolders.ratio('/content/Dataset/json', output='/content/Dataset/labels', seed=2023, ratio=(0.8, 0.2))\n","\n","splitfolders.ratio('/content/Dataset/jpg', output='/content/Dataset/images', seed=2023, ratio=(0.8, 0.2))"],"metadata":{"id":"1qfGCSqy_kL0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679628671624,"user_tz":-540,"elapsed":5964,"user":{"displayName":"이신비","userId":"04527371589362270556"}},"outputId":"c000b8ee-e19d-4b4c-ecb2-85f1a98cc08f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: split-folders in /usr/local/lib/python3.9/dist-packages (0.5.1)\n"]},{"output_type":"stream","name":"stderr","text":["Copying files: 5218 files [00:00, 9508.31 files/s]\n","Copying files: 5218 files [00:02, 1947.01 files/s]\n"]}]},{"cell_type":"code","source":["\n","# for i in range (8):\n","#     for path in os.listdir('/content/Dataset/images/train' +'/'+ won_list[i]):\n","#         shutil.move('/content/Dataset/images/train'+'/'+won_list[i]+'/'+path, '/content/Dataset/images/train')\n","#     for path in os.listdir('/content/Dataset/images/val' +'/'+ won_list[i]):\n","#         shutil.move('/content/Dataset/images/val'+'/'+won_list[i]+'/'+path, '/content/Dataset/images/val')\n","#     for path in os.listdir('/content/Dataset/labels/train' +'/'+ won_list[i]):\n","#         shutil.move('/content/Dataset/labels/train'+'/'+won_list[i]+'/'+path, '/content/Dataset/labels/train')\n","#     for path in os.listdir('/content/Dataset/labels/val' +'/'+ won_list[i]):\n","#         shutil.move('/content/Dataset/labels/val'+'/'+won_list[i]+'/'+path, '/content/Dataset/labels/val')"],"metadata":{"id":"5PizdZl5pC-M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import shutil\n","# shutil.rmtree('/content/Dataset')\n","# shutil.rmtree('/content/Dataset/jpg')\n","# shutil.rmtree('/content/Dataset/json')\n","\n","# for i in range (8):\n","#     shutil.rmtree('/content/Dataset/images/train' +'/'+ won_list[i])\n","#     shutil.rmtree('/content/Dataset/images/val' +'/'+ won_list[i])\n","#     shutil.rmtree('/content/Dataset/labels/train' +'/'+ won_list[i])\n","#     shutil.rmtree('/content/Dataset/labels/val' +'/'+ won_list[i])"],"metadata":{"id":"iaUTxo8jRHEA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 추출 후 이미지 갯수 확인\n","print(len(os.listdir('/content/Dataset/images/train')))\n","print(len(os.listdir('/content/Dataset/labels/train')))\n","print(len(os.listdir('/content/Dataset/images/val')))\n","print(len(os.listdir('/content/Dataset/labels/val')))\n","print(len(os.listdir('/content/Dataset/images')))\n","print(len(os.listdir('/content/Dataset/labels')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bfCUXFFvQaij","executionInfo":{"status":"ok","timestamp":1679628683494,"user_tz":-540,"elapsed":485,"user":{"displayName":"이신비","userId":"04527371589362270556"}},"outputId":"07939d5f-1a9b-4daa-aa1d-47442e133806"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4172\n","4172\n","1046\n","1046\n","2\n","2\n"]}]},{"cell_type":"markdown","source":["### (2) json에서 정보 추출\n","---\n","- **세부요구사항**\n","    - json 파일에서 필요한 정보를 추출하세요:\n","        - 위치 정보 : x1, x2, y1, y2\n","        - 박스 정보 : shape_type\n","        - 클래스 정보 : labels\n","    - 화폐당 하나의 클래스로 변경하세요.\n","        - json 파일에는 화폐 클래스가 앞뒷면으로 구분되어 있습니다.\n","        - 화폐의 앞뒷면 구분을 없애주세요.\n","            - 예시 : 'ten_front', 'ten_back' -> 'ten'\n","    - 화폐의 위치 정보를 YOLO 모델 형식에 맞게 변경 해주세요.\n","        - 사용되는 이미지는 원본에서 1/4로 축소되어 있습니다.\n","        - json 파일의 정보는 원본 기준 데이터이므로 위치 정보 추출을 할 때 x값과 y값을 1/4로 줄여주세요.\n","    - 이렇게 변경된 정보를 YOLO label 형식에 맞게 txt파일로 저장 해 주세요.\n","        - Hint : YOLO Labeling Format [label, x-center, y-center, width-norm, height-norm]\n","---"],"metadata":{"id":"II_hsJ6bKYGn"}},{"cell_type":"code","source":["import os, json, glob"],"metadata":{"id":"MgUoCewjM-Jf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["json_path = '/content/Dataset/labels/'\n","temp_list = ['train', 'val']"],"metadata":{"id":"gBD1Zv9BKaxi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i='/content/Dataset/json/10/10_1138_1.json'\n","with open(i) as f:\n","    data = json.load(f)\n","    label = data['shapes'][0]['label']\n","    if label.endswith(\"back\"):\n","        label = data['shapes'][0]['label'][:-5]\n","    elif label.endswith(\"front\"):\n","        label = data['shapes'][0]['label'][:-6]\n","    point = data['shapes'][0]['points']\n","    x = ((point[0][0] + point[0][1])/data['imageWidth'])/2\n","    y = ((point[1][0] + point[1][1])/data['imageHeight'])/2\n","    w = (point[1][0] - point[0][0]) / data['imageWidth']\n","    h = (point[1][1] - point[0][1]) / data['imageHeight']\n","print(x, y, w, h)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EVptgz1i97Mg","executionInfo":{"status":"ok","timestamp":1679628689521,"user_tz":-540,"elapsed":440,"user":{"displayName":"이신비","userId":"04527371589362270556"}},"outputId":"b2ebad81-60c1-491e-81ce-a9c5b0e2d03a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.4733636286055641 0.5162725249999999 0.21551567055811569 0.16086285417306698\n"]}]},{"cell_type":"code","source":["########################\n","# 이 셀부터 코드 작성하세요\n","# Json 파일에서 필요한 정보만 골라 txt로 바꾸는 작업임을 기억하세요!\n","########################\n","File_List = glob.glob(json_path + '*/*')\n","for i in File_List:\n","    try:\n","        with open(i) as f:\n","            data = json.load(f)\n","            label = data['shapes'][0]['label']\n","            if label.endswith(\"back\"):\n","                label = data['shapes'][0]['label'][:-5]\n","            elif label.endswith(\"front\"):\n","                label = data['shapes'][0]['label'][:-6]\n","            point = data['shapes'][0]['points']\n","            x = ((point[0][0] + point[1][0])/data['imageWidth'])/2\n","            y = ((point[0][1] + point[1][1])/data['imageHeight'])/2\n","            w = (point[1][0] - point[0][0]) / data['imageWidth']\n","            h = (point[1][1] - point[0][1]) / data['imageHeight']\n","\n","            \n","            if  'Ten' in label:\n","                temp = 0\n","            if 'Fifty' in label:\n","                temp = 1\n","            if 'Hundred'  in label:\n","                temp = 2\n","            if 'Five_Hundred' in label:\n","                temp = 3\n","            if 'Thousand' in label:\n","                temp = 4\n","            if 'Five_Thousand' in label:\n","                temp = 5\n","            if 'Ten_Thousand' in label:\n","                temp = 6\n","            if 'Fifty_Thousand' in label:\n","                temp = 7\n","\n","            \n","            file = open(i, 'w')\n","            file.write(f'{temp} {x} {y} {w} {h}')\n","            file.close()\n","            os.rename(i, i[:-4] + 'txt')\n","            \n","    except json.JSONDecodeError:\n","        print('NO')\n","           "],"metadata":{"id":"Mzh2Y8doMEK1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tOQeEhApesWR"},"source":["### (3) 데이터셋 정보가 담긴 파일 생성\n","---\n","- **세부요구사항**\n","    - 파일 안에 있어야 할 정보는 아래와 같습니다.\n","        - 학습할 클래스 이름 정보\n","        - 학습할 클래스 수 정보\n","        - Training, Validation 데이터셋 위치 정보\n","---\n","- 가장 대중적으로 이용하는 라이브러리는 yaml 입니다.\n","    - [yaml document](https://pyyaml.org/wiki/PyYAMLDocumentation)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pu1iQfQolBhJ"},"outputs":[],"source":["import yaml"]},{"cell_type":"code","source":["won_dict = {0:'10', 1:'50', 2:'100', 3:'500', 4:'1000', 5:'5000', 6:'10000', 7:'50000'}"],"metadata":{"id":"t1_uOeXcSvv3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qvMQcHirmSnD"},"outputs":[],"source":["########################\n","# 이 셀부터 코드 작성하세요\n","########################\n","# data = {\n","#     'class_names' : [won_dict[i] for i in range(len(won_dict))],\n","#     'num_classes' : len(won_dict),\n","#     'datasets' : {\n","#         'train' : ['/content/Dataset/images/train'],\n","#         'val' : ['/content/Dataset/images/val']\n","#     }\n","# }\n","# with open('/content/Dataset/money.yaml', 'w') as f :\n","#     yaml.dump(data, f)"]},{"cell_type":"code","source":["# names : ['10', '50', '100', '500', '1000', '5000', '10000', '50000']\n","# path : /content/Dataset\n","# train : images/train\n","# val : images/val\n","# nc : 8"],"metadata":{"id":"z2afiDCoP6ny"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.모델링"],"metadata":{"id":"3btFvySXi2dt"}},{"cell_type":"markdown","metadata":{"id":"0pQ2gRbTYgLL"},"source":["### (1) 모델 라이브러리 설치\n","---"]},{"cell_type":"code","source":["!pip install jedi"],"metadata":{"id":"73a1l-ZQuHyF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679628721991,"user_tz":-540,"elapsed":3567,"user":{"displayName":"이신비","userId":"04527371589362270556"}},"outputId":"f303fad4-a2e7-4095-cab5-10346b47c1d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: jedi in /usr/local/lib/python3.9/dist-packages (0.18.2)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi) (0.8.3)\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/ultralytics/yolov5"],"metadata":{"id":"Biyr9AHkMyNf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679628723774,"user_tz":-540,"elapsed":409,"user":{"displayName":"이신비","userId":"04527371589362270556"}},"outputId":"7efb1339-0a30-426c-84f0-4bc0a3580b8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'yolov5' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["## yolov5 폴더 requirements.txt 수정 필요\n","## setuptools<=64.0.2\n","\n","temp_str = 'setuptools<=64.0.2\\n' \n","\n","f = open('/content/yolov5/requirements.txt', 'r') \n","f_str = f.readlines() \n","f.close() \n","\n","f2 = open('/content/yolov5/requirements.txt', 'w') \n","\n","for idx, val in enumerate(f_str) : \n","    if 'setuptools' in val : \n","        idx_v = idx \n","        f_str.remove(val) \n","        f_str.insert(idx_v, temp_str) \n","        \n","for val in f_str : \n","    f2.write(val) \n","\n","f2.close()"],"metadata":{"id":"W3JjyVOpg26s"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6xD6tBTdMyNg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679628732766,"user_tz":-540,"elapsed":3898,"user":{"displayName":"이신비","userId":"04527371589362270556"}},"outputId":"6b3480f6-7540-4a8f-fea1-4b2f02c48332"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (3.1.31)\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (4.7.0.72)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (8.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (5.9.4)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (2.27.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (1.10.1)\n","Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 15)) (1.13.1+cu116)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 16)) (0.14.1+cu116)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 17)) (4.65.0)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 21)) (2.11.2)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 26)) (1.4.4)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 27)) (0.12.2)\n","Requirement already satisfied: setuptools<=64.0.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 41)) (64.0.2)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.10)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (3.0.9)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.0.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (23.0)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (5.12.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (4.39.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (0.11.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.5.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.4.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.51.3)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.2.3)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.40.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.8.1)\n","Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.19.6)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.4.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.16.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 26)) (2022.7.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.16.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (5.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.3.1)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->-r requirements.txt (line 6)) (3.15.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 21)) (6.1.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.1.2)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.2.2)\n"]}],"source":["!cd yolov5; pip install -r requirements.txt"]},{"cell_type":"markdown","source":["### (2) 가중치 파일 다운로드\n","---\n","- **세부요구사항**\n","    - 모델 개발자가 제공하는 사전 학습 가중치 파일을 다운로드 하세요.\n","        - 해당 과정이 불필요하다면 넘어가셔도 됩니다!\n","---"],"metadata":{"id":"_mHMAspjR6Xp"}},{"cell_type":"code","source":["!mkdir /content/yolov5/pretrained"],"metadata":{"id":"IY3f8vIdssqQ","executionInfo":{"status":"ok","timestamp":1679628735084,"user_tz":-540,"elapsed":423,"user":{"displayName":"이신비","userId":"04527371589362270556"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cf430308-4b02-4c45-b9be-52bd7b243ed9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘/content/yolov5/pretrained’: File exists\n"]}]},{"cell_type":"code","source":["########################\n","# 이 셀부터 코드 작성하세요\n","########################\n","!wget -O /content/yolov5/pretrained/yolov5m.pt https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt"],"metadata":{"id":"sSVIqkMLDIOd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679628737031,"user_tz":-540,"elapsed":261,"user":{"displayName":"이신비","userId":"04527371589362270556"}},"outputId":"d8b786d4-65e5-4e49-cc40-b0c738136f98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-03-24 03:31:46--  https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/7acc87ed-9e1f-4d4a-8bdc-0912393948df?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230324%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230324T033146Z&X-Amz-Expires=300&X-Amz-Signature=6f7f3a05754ed799218b20e6cde803a7603e469f4cc7759c4d330265d1adefc6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5m.pt&response-content-type=application%2Foctet-stream [following]\n","--2023-03-24 03:31:46--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/7acc87ed-9e1f-4d4a-8bdc-0912393948df?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230324%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230324T033146Z&X-Amz-Expires=300&X-Amz-Signature=6f7f3a05754ed799218b20e6cde803a7603e469f4cc7759c4d330265d1adefc6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5m.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 42806829 (41M) [application/octet-stream]\n","Saving to: ‘/content/yolov5/pretrained/yolov5m.pt’\n","\n","/content/yolov5/pre 100%[===================>]  40.82M   190MB/s    in 0.2s    \n","\n","2023-03-24 03:31:47 (190 MB/s) - ‘/content/yolov5/pretrained/yolov5m.pt’ saved [42806829/42806829]\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"W8-5lC4mfbwT"},"source":["### (3) 학습 : train.py\n","---\n","- **세부요구사항**\n","    - UltraLytics YOLO v5에는 아래의 데이터가 필요합니다.\n","        - 데이터셋 정보가 담긴 yaml 파일\n","        - 사용하려는 모델 구조에 대한 yaml 파일\n","        - 사용하려는 모델의 가중치 파일\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4AYFDMaVfmTK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ed203e8a-7cdd-4c7b-d404-73c05b5bd28c","executionInfo":{"status":"ok","timestamp":1679642850897,"user_tz":-540,"elapsed":4781249,"user":{"displayName":"이신비","userId":"04527371589362270556"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/yolov5/pretrained/yolov5m.pt, cfg=/content/yolov5/models/yolov5m.yaml, data=/content/Dataset/money.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=1000, batch_size=16, imgsz=320, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=trained, name=train, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=7, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v7.0-128-gb96f35c Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir trained', view at http://localhost:6006/\n","2023-03-24 06:07:23.378251: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-03-24 06:07:24.418234: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n","2023-03-24 06:07:24.418348: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n","2023-03-24 06:07:24.418368: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","Overriding model.yaml nc=80 with nc=8\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n","  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n","  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n","  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n","  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n","  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n","  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n","  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n","  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n","  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n"," 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n"," 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n"," 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n"," 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 24      [17, 20, 23]  1     52533  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n","YOLOv5m summary: 291 layers, 20899605 parameters, 20899605 gradients, 48.3 GFLOPs\n","\n","Transferred 474/481 items from /content/yolov5/pretrained/yolov5m.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Dataset/labels/train.cache... 4172 images, 0 backgrounds, 0 corrupt: 100% 4172/4172 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Dataset/labels/val.cache... 1046 images, 0 backgrounds, 0 corrupt: 100% 1046/1046 [00:00<?, ?it/s]\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.25 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to trained/train/labels.jpg... \n","Image sizes 320 train, 320 val\n","Using 4 dataloader workers\n","Logging results to \u001b[1mtrained/train\u001b[0m\n","Starting training for 1000 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      0/999      1.73G     0.0577    0.01798    0.05281         31        320: 100% 261/261 [01:09<00:00,  3.77it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  4.12it/s]\n","                   all       1046       1046      0.258      0.564      0.422      0.278\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      1/999      2.26G    0.04012    0.01141    0.03491         22        320: 100% 261/261 [01:04<00:00,  4.02it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  4.11it/s]\n","                   all       1046       1046      0.471      0.814      0.694      0.398\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      2/999      2.26G    0.03696   0.008703    0.02165         24        320: 100% 261/261 [01:04<00:00,  4.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.16it/s]\n","                   all       1046       1046      0.558      0.916      0.719      0.505\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      3/999      2.26G    0.02985   0.007507    0.01953         24        320: 100% 261/261 [01:05<00:00,  3.99it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.35it/s]\n","                   all       1046       1046      0.639      0.935      0.757      0.519\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      4/999      2.26G    0.02533   0.006803    0.01803         19        320: 100% 261/261 [01:03<00:00,  4.09it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  4.10it/s]\n","                   all       1046       1046      0.777      0.896      0.837      0.707\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      5/999      2.26G    0.02306    0.00636    0.01666         27        320: 100% 261/261 [01:03<00:00,  4.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.16it/s]\n","                   all       1046       1046      0.813      0.831      0.871      0.702\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      6/999      2.26G    0.02159   0.006033     0.0156         25        320: 100% 261/261 [01:03<00:00,  4.10it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  4.02it/s]\n","                   all       1046       1046      0.827      0.832      0.885      0.768\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      7/999      2.26G    0.02032   0.005929    0.01455         27        320: 100% 261/261 [01:04<00:00,  4.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.16it/s]\n","                   all       1046       1046      0.887      0.873      0.924      0.778\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      8/999      2.26G    0.01942    0.00571      0.014         25        320: 100% 261/261 [01:03<00:00,  4.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  4.12it/s]\n","                   all       1046       1046      0.901      0.893      0.934      0.801\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      9/999      2.26G    0.01866   0.005568    0.01298         27        320: 100% 261/261 [01:03<00:00,  4.09it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  4.07it/s]\n","                   all       1046       1046      0.883       0.92      0.952       0.79\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     10/999      2.26G    0.01828   0.005466    0.01213         29        320: 100% 261/261 [01:03<00:00,  4.09it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.13it/s]\n","                   all       1046       1046      0.806      0.799       0.89      0.795\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     11/999      2.26G    0.01768   0.005361    0.01168         27        320: 100% 261/261 [01:04<00:00,  4.06it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.27it/s]\n","                   all       1046       1046      0.875      0.824       0.92      0.822\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     12/999      2.26G    0.01716    0.00527    0.01144         24        320: 100% 261/261 [01:04<00:00,  4.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.29it/s]\n","                   all       1046       1046      0.924      0.909      0.957       0.84\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     13/999      2.26G    0.01678    0.00522    0.01043         27        320: 100% 261/261 [01:03<00:00,  4.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.34it/s]\n","                   all       1046       1046      0.927      0.888      0.963      0.874\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     14/999      2.26G    0.01584   0.005126   0.009814         28        320: 100% 261/261 [01:03<00:00,  4.09it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.40it/s]\n","                   all       1046       1046      0.942      0.938       0.98      0.897\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     15/999      2.26G     0.0154   0.004914   0.009756         34        320: 100% 261/261 [01:04<00:00,  4.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.43it/s]\n","                   all       1046       1046      0.932      0.934      0.979       0.88\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     16/999      2.26G    0.01566   0.004983   0.009242         23        320: 100% 261/261 [01:05<00:00,  4.01it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.52it/s]\n","                   all       1046       1046      0.934      0.914      0.961      0.878\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     17/999      2.26G    0.01491   0.004888   0.009293         24        320: 100% 261/261 [01:04<00:00,  4.04it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.27it/s]\n","                   all       1046       1046      0.907      0.921       0.96      0.883\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     18/999      2.26G    0.01471   0.004736   0.008848         27        320: 100% 261/261 [01:04<00:00,  4.05it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.19it/s]\n","                   all       1046       1046       0.95      0.936      0.975       0.89\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     19/999      2.26G    0.01443   0.004666   0.008167         20        320: 100% 261/261 [01:04<00:00,  4.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.15it/s]\n","                   all       1046       1046      0.948      0.972      0.986      0.911\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     20/999      2.26G    0.01461   0.004684   0.008192         22        320: 100% 261/261 [01:04<00:00,  4.03it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  4.10it/s]\n","                   all       1046       1046      0.975      0.978      0.989      0.907\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     21/999      2.26G     0.0138   0.004624   0.007939         23        320: 100% 261/261 [01:04<00:00,  4.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.24it/s]\n","                   all       1046       1046      0.964      0.925      0.976      0.899\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     22/999      2.26G    0.01382   0.004559   0.007905         25        320: 100% 261/261 [01:03<00:00,  4.10it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.13it/s]\n","                   all       1046       1046      0.982      0.969       0.99      0.925\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     23/999      2.26G    0.01358   0.004561   0.007226         30        320: 100% 261/261 [01:04<00:00,  4.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.17it/s]\n","                   all       1046       1046      0.953      0.933      0.979      0.913\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     24/999      2.26G    0.01372   0.004502   0.007356         24        320: 100% 261/261 [01:03<00:00,  4.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.17it/s]\n","                   all       1046       1046      0.963      0.974      0.987      0.929\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     25/999      2.26G    0.01312   0.004348   0.006753         23        320: 100% 261/261 [01:04<00:00,  4.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.23it/s]\n","                   all       1046       1046      0.987      0.976      0.992      0.932\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     26/999      2.26G    0.01312   0.004404   0.007405         27        320: 100% 261/261 [01:03<00:00,  4.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.20it/s]\n","                   all       1046       1046      0.987      0.973      0.991       0.93\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     27/999      2.26G    0.01274   0.004326   0.006912         22        320: 100% 261/261 [01:03<00:00,  4.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.30it/s]\n","                   all       1046       1046      0.971      0.915      0.978      0.914\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     28/999      2.26G    0.01287   0.004412   0.006958         40        320: 100% 261/261 [01:04<00:00,  4.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.50it/s]\n","                   all       1046       1046      0.975      0.966      0.989      0.931\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     29/999      2.26G    0.01286   0.004367   0.006498         26        320: 100% 261/261 [01:04<00:00,  4.06it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.23it/s]\n","                   all       1046       1046      0.979      0.957       0.99      0.918\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     30/999      2.26G    0.01235   0.004259   0.006541         28        320: 100% 261/261 [01:05<00:00,  4.01it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.51it/s]\n","                   all       1046       1046      0.971      0.969      0.986      0.935\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     31/999      2.26G    0.01246   0.004245   0.006583         23        320: 100% 261/261 [01:04<00:00,  4.05it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.16it/s]\n","                   all       1046       1046      0.986      0.969       0.99       0.94\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     32/999      2.26G    0.01234   0.004225   0.006472         26        320: 100% 261/261 [01:04<00:00,  4.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.19it/s]\n","                   all       1046       1046      0.973      0.976      0.993      0.937\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     33/999      2.26G    0.01218   0.004173   0.005931         20        320: 100% 261/261 [01:03<00:00,  4.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  3.87it/s]\n","                   all       1046       1046      0.995      0.991      0.993      0.946\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     34/999      2.26G     0.0118   0.004137   0.006029         25        320: 100% 261/261 [01:03<00:00,  4.10it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  3.90it/s]\n","                   all       1046       1046       0.99      0.974      0.992      0.942\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     35/999      2.26G    0.01175   0.004118   0.005981         24        320: 100% 261/261 [01:03<00:00,  4.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  3.99it/s]\n","                   all       1046       1046      0.985       0.98      0.992      0.949\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     36/999      2.26G    0.01211   0.004048   0.005772         27        320: 100% 261/261 [01:04<00:00,  4.05it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  4.07it/s]\n","                   all       1046       1046      0.983       0.98      0.993      0.951\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     37/999      2.26G    0.01143   0.004058   0.005358         21        320: 100% 261/261 [01:03<00:00,  4.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  4.03it/s]\n","                   all       1046       1046      0.987      0.973      0.991      0.948\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     38/999      2.26G    0.01178   0.004046   0.005506         23        320: 100% 261/261 [01:03<00:00,  4.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.14it/s]\n","                   all       1046       1046      0.991      0.974      0.993      0.949\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     39/999      2.26G     0.0117   0.004036   0.005498         34        320: 100% 261/261 [01:03<00:00,  4.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  4.06it/s]\n","                   all       1046       1046      0.991      0.991      0.994      0.951\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     40/999      2.26G     0.0114   0.004066   0.005473         26        320: 100% 261/261 [01:04<00:00,  4.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.14it/s]\n","                   all       1046       1046      0.968      0.983      0.991      0.952\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     41/999      2.26G    0.01135   0.004009   0.005712         26        320: 100% 261/261 [01:04<00:00,  4.04it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  3.89it/s]\n","                   all       1046       1046      0.996      0.981      0.995      0.951\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     42/999      2.26G    0.01148   0.004008    0.00538         21        320: 100% 261/261 [01:04<00:00,  4.03it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  3.99it/s]\n","                   all       1046       1046      0.991       0.99      0.995      0.955\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     43/999      2.26G    0.01116   0.003921    0.00535         32        320: 100% 261/261 [01:04<00:00,  4.05it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.17it/s]\n","                   all       1046       1046      0.992      0.999      0.995      0.956\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     44/999      2.26G    0.01127   0.003993   0.005394         21        320: 100% 261/261 [01:03<00:00,  4.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  4.06it/s]\n","                   all       1046       1046      0.985       0.98      0.993      0.961\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     45/999      2.26G    0.01103   0.003962   0.005705         22        320: 100% 261/261 [01:04<00:00,  4.02it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.15it/s]\n","                   all       1046       1046      0.983      0.983      0.992      0.959\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     46/999      2.26G    0.01103    0.00393   0.005168         22        320: 100% 261/261 [01:04<00:00,  4.06it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  4.11it/s]\n","                   all       1046       1046      0.984      0.985      0.992      0.963\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     47/999      2.26G    0.01088   0.003908   0.005219         29        320: 100% 261/261 [01:03<00:00,  4.09it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.22it/s]\n","                   all       1046       1046      0.984      0.985      0.993      0.958\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     48/999      2.26G    0.01114   0.003935    0.00518         19        320: 100% 261/261 [01:04<00:00,  4.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.39it/s]\n","                   all       1046       1046      0.988      0.982      0.993      0.956\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     49/999      2.26G    0.01086   0.003907   0.004799         34        320: 100% 261/261 [01:03<00:00,  4.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.34it/s]\n","                   all       1046       1046       0.98      0.987      0.994      0.959\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     50/999      2.26G    0.01085   0.003886   0.004507         34        320: 100% 261/261 [01:04<00:00,  4.04it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.39it/s]\n","                   all       1046       1046      0.986      0.991      0.991      0.962\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     51/999      2.26G    0.01068   0.003913   0.004699         23        320: 100% 261/261 [01:04<00:00,  4.02it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.42it/s]\n","                   all       1046       1046      0.996      0.991      0.994      0.966\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     52/999      2.26G    0.01058   0.003796   0.004795         24        320: 100% 261/261 [01:04<00:00,  4.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  3.97it/s]\n","                   all       1046       1046      0.994      0.994      0.995      0.967\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     53/999      2.26G    0.01059   0.003775   0.004467         27        320: 100% 261/261 [01:04<00:00,  4.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  4.05it/s]\n","                   all       1046       1046      0.993      0.991      0.994      0.967\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     54/999      2.26G    0.01056   0.003843   0.004801         28        320: 100% 261/261 [01:04<00:00,  4.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.15it/s]\n","                   all       1046       1046      0.992      0.977      0.994      0.965\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     55/999      2.26G    0.01063   0.003767   0.004794         21        320: 100% 261/261 [01:03<00:00,  4.09it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  4.01it/s]\n","                   all       1046       1046      0.993      0.993      0.995      0.966\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     56/999      2.26G    0.01032   0.003744   0.004314         27        320: 100% 261/261 [01:04<00:00,  4.06it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  3.98it/s]\n","                   all       1046       1046      0.992       0.99      0.995      0.969\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     57/999      2.26G    0.01055   0.003788   0.004466         25        320: 100% 261/261 [01:04<00:00,  4.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  3.99it/s]\n","                   all       1046       1046      0.996      0.991      0.995      0.971\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     58/999      2.26G    0.01033   0.003684   0.004286         26        320: 100% 261/261 [01:03<00:00,  4.10it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  4.09it/s]\n","                   all       1046       1046      0.997      0.999      0.995      0.971\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     59/999      2.26G    0.01019   0.003761   0.004203         23        320: 100% 261/261 [01:03<00:00,  4.10it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  4.04it/s]\n","                   all       1046       1046      0.992      0.997      0.995      0.968\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     60/999      2.26G    0.01034    0.00378    0.00397         23        320: 100% 261/261 [01:03<00:00,  4.09it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.33it/s]\n","                   all       1046       1046      0.993      0.997      0.995      0.969\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     61/999      2.26G     0.0103   0.003677   0.004376         29        320: 100% 261/261 [01:03<00:00,  4.10it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.20it/s]\n","                   all       1046       1046      0.996      0.996      0.995      0.966\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     62/999      2.26G    0.01017   0.003713    0.00427         26        320: 100% 261/261 [01:04<00:00,  4.05it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.46it/s]\n","                   all       1046       1046      0.997      0.992      0.995      0.968\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     63/999      2.26G    0.01039   0.003746   0.004175         36        320: 100% 261/261 [01:04<00:00,  4.03it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.35it/s]\n","                   all       1046       1046      0.994       0.99      0.995      0.965\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     64/999      2.26G    0.01009   0.003567   0.004118         27        320: 100% 261/261 [01:04<00:00,  4.03it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.26it/s]\n","                   all       1046       1046      0.989       0.99      0.995      0.968\n","Stopping training early as no improvement observed in last 7 epochs. Best results observed at epoch 57, best model saved as best.pt.\n","To update EarlyStopping(patience=7) pass a new patience value, i.e. `python train.py --patience 300` or use `--patience 0` to disable EarlyStopping.\n","\n","65 epochs completed in 1.318 hours.\n","Optimizer stripped from trained/train/weights/last.pt, 42.1MB\n","Optimizer stripped from trained/train/weights/best.pt, 42.1MB\n","\n","Validating trained/train/weights/best.pt...\n","Fusing layers... \n","YOLOv5m summary: 212 layers, 20881221 parameters, 0 gradients, 47.9 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:09<00:00,  3.64it/s]\n","                   all       1046       1046      0.996      0.991      0.995      0.971\n","                    10       1046         88          1          1      0.995      0.964\n","                    50       1046         88      0.985          1      0.995      0.948\n","                   100       1046         88          1      0.934      0.995      0.955\n","                   500       1046         88      0.984          1      0.995      0.975\n","                  1000       1046        172          1      0.996      0.995      0.983\n","                  5000       1046        174      0.999          1      0.995       0.98\n","                 10000       1046        174      0.999          1      0.995      0.982\n","                 50000       1046        174      0.999          1      0.995      0.981\n","Results saved to \u001b[1mtrained/train\u001b[0m\n"]}],"source":["########################\n","# 이 셀부터 코드 작성하세요\n","########################\n","!cd yolov5; python train.py \\\n","    --data '/content/Dataset/money.yaml' \\\n","    --cfg '/content/yolov5/models/yolov5m.yaml' \\\n","    --weights '/content/yolov5/pretrained/yolov5m.pt' \\\n","    --epochs 1000 \\\n","    --patience 7 \\\n","    --img 320 \\\n","    --project 'trained' \\\n","    --name 'train' \\\n","    --exist-ok \\\n","    # --device cpu"]},{"cell_type":"code","source":["function ClickConnect(){\n","    console.log(\"코랩 연결 끊김 방지\"); \n","    document.querySelector(\"colab-toolbar-button#connect\").click() \n","}\n","setInterval(ClickConnect, 60 * 1000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136},"id":"FynEXZcXScyG","executionInfo":{"status":"error","timestamp":1679636557604,"user_tz":-540,"elapsed":676,"user":{"displayName":"이신비","userId":"04527371589362270556"}},"outputId":"a2179e58-6055-47d2-abc4-1dc0f1ad6c43"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-b32b2eaebf57>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    function ClickConnect(){\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"markdown","metadata":{"id":"u2YESAa5fc4M"},"source":["## 4.탐지 : detect.py\n","---\n","- **세부요구사항**\n","    - 학습 과정에서 생성된 가중치 파일을 이용하세요.\n","    - IoU threshold를 0.25 이하로 설정하세요.\n","    - confidence threshold를 0.75 이상으로 설정하세요.\n","---\n","- 여러분이 **직접 촬영한 화폐 사진과 동영상**을 탐지 과정에 이용하여 결과를 확인하세요.\n","    - 조건\n","        1. 화폐의 수를 늘려가며 촬영 해보세요.\n","            - ex) 50원 하나, 50원 둘, 50원 셋, ...\n","        2. 화폐의 종류를 늘려가며 촬영 해보세요.\n","            - ex) 50원 하나와 100원 하나, 50원 하나와 100원 하나와 1000원 하나, ...\n","        3. 사진은 최소 30장 이상, 동영상은 최소 하나 이상 촬영하여 사용 해보세요.\n","---"]},{"cell_type":"code","source":["########################\n","# 이 셀부터 코드 작성하세요\n","########################\n","!cd yolov5; python detect.py \\\n","    --weights '/content/yolov5/trained/train/weights/best.pt' \\\n","    --source '/content/yolov5/data/images/' \\\n","    --project '/content/yolov5/detected' \\\n","    --name 'images' \\\n","    --img 320 \\\n","    --conf-thres 0.75 \\\n","    --iou-thres 0.25 \\\n","    --line-thickness 2 \\\n","    --exist-ok \n","    # --device CPU"],"metadata":{"id":"9rK0ClfTcjEZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679642998446,"user_tz":-540,"elapsed":8476,"user":{"displayName":"이신비","userId":"04527371589362270556"}},"outputId":"cf63c9dd-ca3d-4352-dc24-867b7bc8f97b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/trained/train/weights/best.pt'], source=/content/yolov5/data/images/, data=data/coco128.yaml, imgsz=[320, 320], conf_thres=0.75, iou_thres=0.25, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/content/yolov5/detected, name=images, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v7.0-128-gb96f35c Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","YOLOv5m summary: 212 layers, 20881221 parameters, 0 gradients, 47.9 GFLOPs\n","image 1/4 /content/yolov5/data/images/KakaoTalk_20230324_095934678_01.jpg: 320x256 1 500, 16.2ms\n","image 2/4 /content/yolov5/data/images/KakaoTalk_20230324_142823093.jpg: 320x256 (no detections), 12.6ms\n","image 3/4 /content/yolov5/data/images/bus.jpg: 320x256 (no detections), 12.4ms\n","image 4/4 /content/yolov5/data/images/zidane.jpg: 192x320 (no detections), 14.4ms\n","Speed: 0.3ms pre-process, 13.9ms inference, 0.6ms NMS per image at shape (1, 3, 320, 320)\n","Results saved to \u001b[1m/content/yolov5/detected/images\u001b[0m\n"]}]},{"cell_type":"code","source":["from IPython.display import Image\n","from google.colab import files"],"metadata":{"id":"sft7HlEbEiy5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Image(filename='/content/yolov5/data/images/KakaoTalk_20230324_095934678_01.jpg', width=320)"],"metadata":{"id":"jSEpFJVIEjdC","colab":{"base_uri":"https://localhost:8080/","height":444,"output_embedded_package_id":"19e8c9ry52Pq5aFS2Lk5HoOjhDIl7r3Vo"},"executionInfo":{"status":"ok","timestamp":1679643040550,"user_tz":-540,"elapsed":6558,"user":{"displayName":"이신비","userId":"04527371589362270556"}},"outputId":"ac119bd7-ce18-4f9b-ce4f-e0517898440a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}